{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1d479b5",
      "metadata": {
        "id": "e1d479b5"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f4d58c2",
      "metadata": {
        "id": "8f4d58c2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "_ = load_dotenv(find_dotenv())\n",
        "os.environ[\"HF_ACCESS_TOKEN\"] = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN\")\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acc6da56",
      "metadata": {
        "id": "acc6da56"
      },
      "outputs": [],
      "source": [
        "import flwr as fl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d76ff75",
      "metadata": {
        "id": "5d76ff75"
      },
      "source": [
        "## 🧑‍🍳 Step 1: Grab the Recipe — Load Your Training Configuration\n",
        "\n",
        "Every great dish starts with a recipe — and in this notebook, that recipe is your config file.\n",
        "\n",
        "In this step, we’re using Hydra to load a YAML configuration that defines all the key ingredients and settings for your federated fine-tuning experiment. Think of it as pulling out the instruction card before cooking.\n",
        "\n",
        "📦 What this does:\n",
        "- Loads a configuration file (in this case, federated_7b.yml) using Hydra.\n",
        "- Prints out the full config in a readable YAML format, thanks to OmegaConf.\n",
        "\n",
        "> Technically you can use `yaml.load()` too because we are using single, static files. Using Hydra allows us to work with more complex, hierarchical nested structures and dynamically override parts of the config from CLI or code like: `python train.py model=transformer optimizer=adam`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "281e1ce5",
      "metadata": {
        "id": "281e1ce5"
      },
      "outputs": [],
      "source": [
        "from hydra import compose, initialize\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "\n",
        "def get_config(config_name: str, config_path: str = \"../config/\"):\n",
        "    with initialize(config_path=config_path, version_base=\"1.1\"):\n",
        "        cfg = compose(config_name=config_name)\n",
        "\n",
        "    return cfg\n",
        "\n",
        "def print_config(config: DictConfig):\n",
        "    print(OmegaConf.to_yaml(config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ba89bec1",
      "metadata": {
        "id": "ba89bec1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/fantastic-enigma/.venv/lib/python3.12/site-packages/hydra/plugins/config_source.py:125: UserWarning: Support for .yml files is deprecated. Use .yaml extension for Hydra config files\n",
            "  deprecation_warning(\n"
          ]
        }
      ],
      "source": [
        "cfg = get_config(\"federated_small.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d6bbeac5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dataset': {'name': 'medalpaca/medical_meadow_medical_flashcards'}, 'model': {'name': 'EleutherAI/pythia-70m', 'quantization': 4, 'gradient_checkpointing': True, 'use_fast_tokenizer': True, 'lora': {'peft_lora_r': 16, 'peft_lora_alpha': 64, 'target_modules': None}}, 'train': {'num_rounds': '${flower.num_rounds}', 'save_every_round': 5, 'learning_rate_max': 5e-05, 'learning_rate_min': 1e-06, 'seq_length': 512, 'padding_side': 'left', 'evaluate_split': False, 'training_arguments': {'output_dir': None, 'learning_rate': None, 'per_device_train_batch_size': 2, 'gradient_accumulation_steps': 1, 'logging_steps': 5, 'num_train_epochs': 1, 'report_to': 'wandb', 'run_name': 'pythia_70m_fedSFT_take3', 'save_steps': 1000, 'save_total_limit': 10, 'gradient_checkpointing': '${model.gradient_checkpointing}', 'lr_scheduler_type': 'constant'}}, 'flower': {'num_clients': 20, 'num_rounds': 2, 'fraction_fit': 0.2, 'client_resources': {'num_cpus': 4, 'num_gpus': 1.0}, 'dp': {'noise_mult': 0.02, 'clip_norm': 0.5}}}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a020b975",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "omegaconf.dictconfig.DictConfig"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82427b45",
      "metadata": {
        "id": "82427b45",
        "outputId": "4eb3eb9d-941f-4e72-a152-128d8965d54d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset:\n",
            "  name: medalpaca/medical_meadow_medical_flashcards\n",
            "model:\n",
            "  name: EleutherAI/pythia-70m\n",
            "  quantization: 4\n",
            "  gradient_checkpointing: true\n",
            "  use_fast_tokenizer: true\n",
            "  lora:\n",
            "    peft_lora_r: 16\n",
            "    peft_lora_alpha: 64\n",
            "    target_modules: null\n",
            "train:\n",
            "  num_rounds: ${flower.num_rounds}\n",
            "  save_every_round: 5\n",
            "  learning_rate_max: 5.0e-05\n",
            "  learning_rate_min: 1.0e-06\n",
            "  seq_length: 512\n",
            "  padding_side: left\n",
            "  evaluate_split: false\n",
            "  training_arguments:\n",
            "    output_dir: null\n",
            "    learning_rate: null\n",
            "    per_device_train_batch_size: 2\n",
            "    gradient_accumulation_steps: 1\n",
            "    logging_steps: 5\n",
            "    num_train_epochs: 1\n",
            "    report_to: wandb\n",
            "    run_name: pythia_70m_fedSFT_take3\n",
            "    save_steps: 1000\n",
            "    save_total_limit: 10\n",
            "    gradient_checkpointing: ${model.gradient_checkpointing}\n",
            "    lr_scheduler_type: constant\n",
            "flower:\n",
            "  num_clients: 20\n",
            "  num_rounds: 2\n",
            "  fraction_fit: 0.2\n",
            "  client_resources:\n",
            "    num_cpus: 4\n",
            "    num_gpus: 1.0\n",
            "  dp:\n",
            "    noise_mult: 0.02\n",
            "    clip_norm: 0.5\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_config(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "218d074b",
      "metadata": {
        "id": "218d074b"
      },
      "source": [
        "## 👨‍🍳 Step 2: Prepare the Ingredients — Format and Partition Your Dataset\n",
        "\n",
        "Every chef knows the importance of prepping ingredients before cooking. In this step, we’re doing exactly that — slicing and dicing our dataset, then portioning it out evenly like we’re handing out bento boxes to 20 hungry students (aka clients).\n",
        "\n",
        "📦 What this does:\n",
        "- 🔪 format_dataset: Cleans and standardizes column names so all partitions speak the same language.\n",
        "- 📦 IidPartitioner: Splits the dataset evenly across clients.\n",
        "- 🍱 FederatedDataset: Applies the partitioning and prepares it for training.\n",
        "- 📊 visualize_partitions: (Optional) Lets us peek at how evenly data is spread.\n",
        "\n",
        "> PS You only need to do this if you're running a Flower simulation. In real production events you have 20 different servers with different datasets! Here we are simulating 20 different servers so that we can run it in a Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdbb33ad",
      "metadata": {
        "id": "bdbb33ad"
      },
      "outputs": [],
      "source": [
        "from flwr_datasets import FederatedDataset\n",
        "from flwr_datasets.partitioner import IidPartitioner\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def format_dataset(dataset):\n",
        "    \"\"\"Helper function to format the dataset\"\"\"\n",
        "\n",
        "    dataset = dataset.remove_columns(['instruction'])\n",
        "    dataset = dataset.rename_column(\"output\", \"response\")\n",
        "    dataset = dataset.rename_column(\"input\", \"instruction\")\n",
        "    return dataset\n",
        "\n",
        "def visualize_partitions(fed_dataset: FederatedDataset):\n",
        "    \"\"\"Helper function to visualize the partitions of the dataset\"\"\"\n",
        "\n",
        "    _ = fed_dataset.load_partition(0)\n",
        "    num_partitions = fed_dataset.partitioners['train'].num_partitions\n",
        "\n",
        "    plt.bar(range(num_partitions), [len(fed_dataset.load_partition(i)) for i in range(num_partitions)])\n",
        "    plt.xticks(range(num_partitions))\n",
        "    plt.xlabel(\"Partition ID\")\n",
        "    plt.ylabel(\"Number of examples\")\n",
        "    plt.title(f\"IID partitioning into {num_partitions} partitions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6ea27b3",
      "metadata": {
        "id": "b6ea27b3",
        "outputId": "d636d015-f830-438a-ecb0-fda2727358db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['instruction', 'response'],\n",
              "    num_rows: 1698\n",
              "})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "partitioner = IidPartitioner(num_partitions=cfg.flower.num_clients)\n",
        "fds = FederatedDataset(\n",
        "    dataset=cfg.dataset.name,\n",
        "    partitioners={\"train\": partitioner}\n",
        ")\n",
        "\n",
        "partition_zero = fds.load_partition(0)\n",
        "\n",
        "format_dataset(partition_zero)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb53e724",
      "metadata": {
        "id": "eb53e724",
        "outputId": "d5950629-49ff-4a88-ff0b-c30b890b7a1d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "visualize_partitions(fds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13104bd0",
      "metadata": {
        "id": "13104bd0"
      },
      "source": [
        "Okay we pretty much have even partitions!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e044507",
      "metadata": {
        "id": "4e044507"
      },
      "source": [
        "## 👨‍🍳 Step 3: Load the Model — Then Estimate Your Grocery Bill\n",
        "\n",
        "Now that we’ve got our ingredients sorted and divided, it’s time to prep the kitchen. Here, we load our model, apply the right quantization, and plug in LoRA adapters to make training lighter. Then we run a quick cost check — like scanning your grocery basket before checkout.\n",
        "\n",
        "📦 What this does:\n",
        "- 🧠 Loads your pretrained model (e.g., Mistral, LLaMA).\n",
        "- 💾 Applies quantization for lower memory use (4-bit/8-bit).\n",
        "- 🎯 Attaches LoRA adapters — a “just train these few layers” approach.\n",
        "- 🧮 Calculates communication costs for 20 simulated clients, across multiple federated rounds.\n",
        "\n",
        "> 📈 Why this matters:\n",
        "> Federated fine-tuning isn’t just about accuracy — it’s also about efficiency. Uploading 7B parameters to 20 clients for 3 rounds? The number of parameters sent by the clients to the server alone can overwhelm it. LoRA cuts that cost by 20x–100x. It's best to have a helper function to budget your bandwidth before the federated feast begins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caa99ca9",
      "metadata": {
        "id": "caa99ca9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    get_peft_model_state_dict,\n",
        "    set_peft_model_state_dict,\n",
        ")\n",
        "from peft.utils import prepare_model_for_kbit_training\n",
        "from trl import DataCollatorForCompletionOnlyLM, SFTTrainer\n",
        "\n",
        "def get_model(model_cfg: DictConfig):\n",
        "    \"\"\"Load model with appropiate quantization config and\n",
        "    other optimizations. Notice here that we are returning the\n",
        "    LoRA model, not the full model.\"\"\"\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    quantization_config = None\n",
        "    model_name = model_cfg.name\n",
        "    if use_cuda:\n",
        "        if model_cfg.quantization == 4:\n",
        "            quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "        elif model_cfg.quantization == 8:\n",
        "            quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Use 4-bit or 8-bit quantization. You passed: {model_cfg.quantization}/\"\n",
        "            )\n",
        "\n",
        "        model_name = model_cfg.name\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=quantization_config,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        low_cpu_mem_usage=True,\n",
        "        token = os.environ[\"HF_ACCESS_TOKEN\"]\n",
        "    )\n",
        "\n",
        "    if use_cuda:\n",
        "        model = prepare_model_for_kbit_training(\n",
        "            model, use_gradient_checkpointing=model_cfg.gradient_checkpointing\n",
        "        )\n",
        "\n",
        "    target_modules = model_cfg.lora.target_modules\n",
        "    if target_modules:\n",
        "        target_modules = list(target_modules)\n",
        "    peft_config = LoraConfig(\n",
        "        r=model_cfg.lora.peft_lora_r,\n",
        "        lora_alpha=model_cfg.lora.peft_lora_alpha,\n",
        "        lora_dropout=0.075,\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "        target_modules=target_modules,\n",
        "    )\n",
        "\n",
        "    peft_model = get_peft_model(model, peft_config)\n",
        "    if not (use_cuda):\n",
        "        peft_model.enable_input_require_grads()\n",
        "\n",
        "    if model_cfg.gradient_checkpointing:\n",
        "        model.config.use_cache = False\n",
        "\n",
        "    return peft_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cec84ee",
      "metadata": {
        "id": "6cec84ee"
      },
      "outputs": [],
      "source": [
        "def compute_communication_costs(config, comm_bw_mbps: float = 20):\n",
        "      \"\"\"\n",
        "      We use Flower's helper function to compute communication costs of federated finetuning.\n",
        "      Get ready to see the savings!\n",
        "      \"\"\"\n",
        "      model = get_model(config.model)\n",
        "\n",
        "      trainable, all_parameters = model.get_nb_trainable_parameters()\n",
        "\n",
        "      total_size = 4*all_parameters/(1024**2)\n",
        "      trainable_size = 4*trainable/(1024**2)\n",
        "\n",
        "      upload_time_total = total_size/(comm_bw_mbps/8)\n",
        "      upload_time_finetune = trainable_size/(comm_bw_mbps/8)\n",
        "\n",
        "      print(f\"Full model:\\n\\t{all_parameters/1e6:.3f} M parameters\\n\\t{total_size:.2f} MB --> upload in {upload_time_total:.2f}s @ {comm_bw_mbps}Mbps\")\n",
        "      print(f\"Finetuned model:\\n\\t{trainable/1e6:.3f} M parameters\\n\\t{trainable_size:.2f} MB --> upload in {upload_time_finetune:.2f}s @ {comm_bw_mbps}Mbps\")\n",
        "      # print(f\"In a {comm_bw_mbps} Mbps channel --> {}\")\n",
        "\n",
        "      num_rounds = config.flower.num_rounds\n",
        "      num_clients_per_round = int(config.flower.num_clients * config.flower.fraction_fit)\n",
        "      print(f\"Federated Learning setting: \"\n",
        "            f\"\\n\\tNumber of rounds: {num_rounds}\"\n",
        "            f\"\\n\\tNumber of clients per round: {num_clients_per_round}\")\n",
        "\n",
        "      print(f\"-----------------------------------------------\")\n",
        "      print(f\"Total Communication costs (Full model): {2*num_rounds*num_clients_per_round*total_size/1024:.1f} GB\")\n",
        "      print(f\"Total Communication costs (Finetuning): {2*num_rounds*num_clients_per_round*trainable_size} MB\")\n",
        "      print(f\"Communication savings: {all_parameters/trainable:.1f}x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5758864",
      "metadata": {
        "id": "b5758864",
        "outputId": "ce4893a0-7fb2-4cfb-cbdc-a081f8d12164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full model:\n",
            "\t70.623 M parameters\n",
            "\t269.41 MB --> upload in 107.76s @ 20Mbps\n",
            "Finetuned model:\n",
            "\t0.197 M parameters\n",
            "\t0.75 MB --> upload in 0.30s @ 20Mbps\n",
            "Federated Learning setting: \n",
            "\tNumber of rounds: 2\n",
            "\tNumber of clients per round: 4\n",
            "-----------------------------------------------\n",
            "Total Communication costs (Full model): 4.2 GB\n",
            "Total Communication costs (Finetuning): 12.0 MB\n",
            "Communication savings: 359.2x\n"
          ]
        }
      ],
      "source": [
        "compute_communication_costs(cfg, comm_bw_mbps=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dab6b9e3",
      "metadata": {
        "id": "dab6b9e3"
      },
      "source": [
        "We save 359x more just by PEFT-ing!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e8d3ae7",
      "metadata": {
        "id": "5e8d3ae7"
      },
      "source": [
        "## 👨‍🍳 Step 4: Prompt Prep — Set the Table for Fine-Tuning\n",
        "\n",
        "Before we can start cooking (i.e., training), we need to set the table properly. That means formatting the prompts, choosing the right tokenizer, and preparing a smart data collator that knows where the “response” part starts.\n",
        "\n",
        "🧠 What’s happening here:\n",
        "- 🔤 Loads the tokenizer and sets a pad token (beginning-of-sequence or end-of-sequence depending on the model).\n",
        "- 📌 Finds the location in the prompt where the model should start predicting — right after \"### Response:\".\n",
        "- 🧼 The `DataCollatorForCompletionOnlyLM` ensures that only the response gets masked for loss — so we train the model only on what it should generate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41691bc0",
      "metadata": {
        "id": "41691bc0"
      },
      "outputs": [],
      "source": [
        "def formatting_prompts_func(example):\n",
        "    # Constructing a standard Alpaca (https://github.com/tatsu-lab/stanford_alpaca#data-release) prompt\n",
        "\n",
        "    output_texts = []\n",
        "    mssg = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
        "    for i in range(len(example[\"instruction\"])):\n",
        "        text = f\"{mssg}\\n### Instruction:\\n{example['instruction'][i]}\\n### Response: {example['response'][i]}\"\n",
        "        output_texts.append(text)\n",
        "    return output_texts\n",
        "\n",
        "def get_tokenizer_and_data_collator_and_prompt_formatting(\n",
        "    model_name: str, use_fast: bool, padding_side: str\n",
        "):\n",
        "    # From: https://huggingface.co/docs/trl/en/sft_trainer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        model_name, use_fast=use_fast, padding_side=padding_side\n",
        "    )\n",
        "\n",
        "    tokenizer.pad_token = (\n",
        "        tokenizer.bos_token if padding_side == \"left\" else tokenizer.eos_token\n",
        "    )\n",
        "    response_template_with_context = \"\\n### Response:\"  # alpaca response tag\n",
        "    response_template_ids = tokenizer.encode(\n",
        "        response_template_with_context, add_special_tokens=False\n",
        "    )[2:]\n",
        "    data_collator = DataCollatorForCompletionOnlyLM(\n",
        "        response_template_ids, tokenizer=tokenizer\n",
        "    )\n",
        "\n",
        "    return tokenizer, data_collator, formatting_prompts_func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a092fe",
      "metadata": {
        "id": "c9a092fe",
        "outputId": "6753cd04-d105-480c-c19d-2ed1103019dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/fantastic-enigma/.venv/lib/python3.12/site-packages/trl/trainer/utils.py:100: DeprecationWarning: This class is deprecated and will be removed in version 0.20.0. To train on completion only, please use the parameter `completion_only_loss` of `SFTConfig` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer, data_collator, formatting_prompts_func = get_tokenizer_and_data_collator_and_prompt_formatting(\n",
        "    cfg.model.name,\n",
        "    cfg.model.use_fast_tokenizer,\n",
        "    cfg.train.padding_side,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "837cc82c",
      "metadata": {
        "id": "837cc82c"
      },
      "source": [
        "## 🍳 Step 5: Crafting the Flower Client – The Heartbeat of Federated Learning\n",
        "\n",
        "In the realm of federated learning, the client is not just a participant; it’s the linchpin that holds the decentralized training process together. Think of it as a dedicated chef in a distributed kitchen, each working with their unique ingredients (data) but following a shared recipe (model architecture).\n",
        "\n",
        "🧠 Understanding the Client’s Role\n",
        "\n",
        "In Flower’s architecture, each client is responsible for:\n",
        "1.\tReceiving the Global Model: The server sends the current global model parameters to the client.\n",
        "2.\tLocal Training: The client trains the model on its local dataset, ensuring data privacy and compliance with data governance policies.\n",
        "3.\tSending Updates: After training, the client sends the updated model parameters back to the server for aggregation.\n",
        "\n",
        "This process allows for collaborative model training without the need to centralize sensitive data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6794ca25",
      "metadata": {
        "id": "6794ca25"
      },
      "source": [
        "Here's our utility function to adjust our learning rate!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea60408",
      "metadata": {
        "id": "eea60408"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def cosine_annealing(\n",
        "    current_round: int,\n",
        "    total_round: int,\n",
        "    lrate_max: float = 0.001,\n",
        "    lrate_min: float = 0.0,\n",
        ") -> float:\n",
        "    \"\"\"Implement cosine annealing learning rate schedule. Strictly speaking this\n",
        "    is not necessary.\"\"\"\n",
        "\n",
        "    cos_inner = math.pi * current_round / total_round\n",
        "    return lrate_min + 0.5 * (lrate_max - lrate_min) * (1 + math.cos(cos_inner))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4a0b8f4",
      "metadata": {
        "id": "f4a0b8f4"
      },
      "source": [
        "🛠️ Implementing the Flower Client\n",
        "\n",
        "Let’s delve into the implementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc38393d",
      "metadata": {
        "id": "dc38393d"
      },
      "outputs": [],
      "source": [
        "from flwr.common import Context\n",
        "from flwr.common.typing import NDArrays, Scalar\n",
        "from flwr.client import NumPyClient\n",
        "\n",
        "from typing import Dict, Tuple, Callable\n",
        "from collections import OrderedDict\n",
        "from trl import SFTConfig\n",
        "\n",
        "def set_parameters(model, parameters: NDArrays) -> None:\n",
        "    \"\"\"Change the parameters of the model using the given ones.\"\"\"\n",
        "\n",
        "    peft_state_dict_keys = get_peft_model_state_dict(model).keys()\n",
        "    params_dict = zip(peft_state_dict_keys, parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    set_peft_model_state_dict(model, state_dict)\n",
        "\n",
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_cfg: DictConfig,\n",
        "        train_cfg: DictConfig,\n",
        "        trainset,\n",
        "        tokenizer,\n",
        "        formatting_prompts_func,\n",
        "        data_collator,\n",
        "        save_path,\n",
        "    ):\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.train_cfg = train_cfg\n",
        "        self.training_arguments = SFTConfig(**train_cfg.training_arguments)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.formatting_prompts_func = formatting_prompts_func\n",
        "        self.data_collator = data_collator\n",
        "        self.save_path = save_path\n",
        "\n",
        "        # instantiate model\n",
        "        self.model = get_model(model_cfg)\n",
        "\n",
        "        self.trainset = trainset\n",
        "\n",
        "    def get_parameters(self, config: Dict[str, Scalar]) -> NDArrays:\n",
        "        \"\"\"Return the parameters of the current net.\"\"\"\n",
        "\n",
        "        state_dict = get_peft_model_state_dict(self.model)\n",
        "        return [val.cpu().numpy() for _, val in state_dict.items()]\n",
        "\n",
        "    def fit(\n",
        "        self, parameters: NDArrays, config: Dict[str, Scalar]\n",
        "    ) -> Tuple[NDArrays, int, Dict]:\n",
        "        \"\"\"Implement distributed fit function for a given client.\"\"\"\n",
        "        set_parameters(self.model, parameters)\n",
        "\n",
        "        new_lr = cosine_annealing(\n",
        "            int(config[\"current_round\"]),\n",
        "            self.train_cfg.num_rounds,\n",
        "            self.train_cfg.learning_rate_max,\n",
        "            self.train_cfg.learning_rate_min,\n",
        "        )\n",
        "\n",
        "        self.training_arguments.learning_rate = new_lr\n",
        "        self.training_arguments.output_dir = self.save_path\n",
        "\n",
        "        evalset = None\n",
        "        if self.train_cfg.evaluate_split:\n",
        "            train_test = self.trainset.train_test_split(test_size=0.1, seed=1234)\n",
        "            trainset = train_test['train']\n",
        "            evalset = train_test['test']\n",
        "        else:\n",
        "            trainset = self.trainset\n",
        "\n",
        "        trainer = SFTTrainer(\n",
        "            model=self.model,\n",
        "            processing_class=self.tokenizer,\n",
        "            args=self.training_arguments,\n",
        "            train_dataset=trainset,\n",
        "            eval_dataset=evalset,\n",
        "            formatting_func=self.formatting_prompts_func,\n",
        "            data_collator=self.data_collator,\n",
        "        )\n",
        "\n",
        "        metrics = {}\n",
        "        if self.train_cfg.evaluate_split:\n",
        "            eval_res = trainer.evaluate()\n",
        "            metrics['eval_loss'] = eval_res['eval_loss']\n",
        "            print(eval_res)\n",
        "\n",
        "        # Do local training\n",
        "        results = trainer.train()\n",
        "\n",
        "        metrics = {**metrics, \"train_loss\": results.training_loss}\n",
        "\n",
        "        return (\n",
        "            self.get_parameters({}),\n",
        "            len(self.trainset),\n",
        "            metrics,\n",
        "        )\n",
        "\n",
        "def gen_client_fn(\n",
        "    fds,\n",
        "    tokenizer,\n",
        "    formatting_prompts_func,\n",
        "    data_collator,\n",
        "    model_cfg: DictConfig,\n",
        "    train_cfg: DictConfig,\n",
        "    save_path: str,\n",
        ") -> Callable[[str], FlowerClient]:\n",
        "    \"\"\"Generate the client function that creates the Flower Clients.\"\"\"\n",
        "\n",
        "    def client_fn(context: Context) -> FlowerClient:\n",
        "        \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "\n",
        "        # Let's get the partition corresponding to the i-th client\n",
        "        partition_id = int(context.node_config[\"partition-id\"])\n",
        "        client_trainset = fds.load_partition(partition_id, \"train\")\n",
        "        client_trainset = client_trainset.remove_columns([\"instruction\"])\n",
        "        client_trainset = client_trainset.rename_column(\"input\", \"instruction\")\n",
        "        client_trainset = client_trainset.rename_column(\"output\", \"response\")\n",
        "        return FlowerClient(\n",
        "            model_cfg,\n",
        "            train_cfg,\n",
        "            client_trainset,\n",
        "            tokenizer,\n",
        "            formatting_prompts_func,\n",
        "            data_collator,\n",
        "            save_path,\n",
        "        ).to_client()\n",
        "\n",
        "    return client_fn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52a19b73",
      "metadata": {
        "id": "52a19b73"
      },
      "outputs": [],
      "source": [
        "from flwr.client.mod import fixedclipping_mod\n",
        "\n",
        "save_path = \"./my_fl_model\"\n",
        "client = fl.client.ClientApp(\n",
        "    client_fn=gen_client_fn(\n",
        "        fds,\n",
        "        tokenizer,\n",
        "        formatting_prompts_func,\n",
        "        data_collator,\n",
        "        cfg.model,\n",
        "        cfg.train,\n",
        "        save_path,\n",
        "    ),\n",
        "    mods=[fixedclipping_mod]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f17d1bb8",
      "metadata": {
        "id": "f17d1bb8"
      },
      "source": [
        "🔍 Key Components Explained\n",
        "- `set_parameters`: Updates the model’s parameters with those received from the server.\n",
        "- `FlowerClient` Class: Inherits from NumPyClient and implements the core methods:\n",
        "- `get_parameters`: Retrieves the current model parameters.\n",
        "- `fit`: Trains the model on local data and returns the updated parameters along with training metrics.\n",
        "- `gen_client_fn`: Generates a function to create `FlowerClient` instances, each corresponding to a unique data partition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff69d0aa",
      "metadata": {
        "id": "ff69d0aa"
      },
      "source": [
        "### 🌐 The Bigger Picture\n",
        "\n",
        "In Flower’s architecture, the client plays a pivotal role in the federated learning process.\n",
        "\n",
        "By handling local training and maintaining data privacy, clients enable the collaborative development of robust models without the need for centralized data storage. This approach is especially beneficial in scenarios where data is sensitive or distributed across various locations.\n",
        "\n",
        "For a deeper dive into Flower’s architecture and the role of clients, you can refer to the [Flower Architecture Documentation](https://flower.ai/docs/framework/explanation-flower-architecture.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66d581e8",
      "metadata": {
        "id": "66d581e8"
      },
      "source": [
        "## 🧠 Step 6: Configuring the Federated Server – Directing the Symphony 🎻\n",
        "\n",
        "While each client trains locally, the server acts as the conductor of the federated learning orchestra. It defines how rounds are configured, how model updates are aggregated, and when models are saved.\n",
        "\n",
        "This cell introduces three essential server-side functions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32b479a8",
      "metadata": {
        "id": "32b479a8"
      },
      "outputs": [],
      "source": [
        "from flwr.common import Context\n",
        "\n",
        "def get_on_fit_config():\n",
        "    \"\"\"\n",
        "    •\tPurpose: This function provides the configuration dictionary sent to each\n",
        "    client before training begins in a given round.\n",
        "\t•\tUse Case: Clients can adapt behaviors (e.g., learning rate schedules) based\n",
        "    on the current round number.\n",
        "\t•\tDesign Pattern: Returns a function (fit_config_fn) that Flower calls at each\n",
        "    round.\n",
        "\n",
        "    🧠 Analogy: This is like giving each chef a new cooking instruction every day\n",
        "    based on how many days the kitchen has been operating.\n",
        "\n",
        "    \"\"\"\n",
        "    def fit_config_fn(server_round: int):\n",
        "        fit_config = {\"current_round\": server_round}\n",
        "        return fit_config\n",
        "\n",
        "    return fit_config_fn\n",
        "\n",
        "def fit_weighted_average(metrics):\n",
        "    \"\"\"\n",
        "    •\tPurpose: Calculates a weighted average of training loss across all clients.\n",
        "    •\tMechanism:\n",
        "        •\tEach client’s training loss is scaled by the number of examples it used.\n",
        "        •\tThis ensures larger datasets have more influence on the final average.\n",
        "    •\tWhy It Matters: Without weighting, small datasets could skew the overall metric.\n",
        "\n",
        "    Example:\n",
        "    # Client 1: 100 examples, loss = 0.5 → 100 * 0.5 = 50\n",
        "    # Client 2: 200 examples, loss = 0.25 → 200 * 0.25 = 50\n",
        "    # Weighted average = (50 + 50) / (100 + 200) = 0.333\n",
        "    \"\"\"\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    losses = [num_examples * m[\"train_loss\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"train_loss\": sum(losses) / sum(examples)}\n",
        "\n",
        "def get_evaluate_fn(model_cfg, save_every_round, total_round, save_path):\n",
        "    \"\"\"\n",
        "    •\tPurpose: Save the global model periodically during training.\n",
        "\t•\tConditions:\n",
        "\t•\tSkip round 0.\n",
        "\t•\tSave if it’s the final round or every n rounds (save_every_round).\n",
        "\t•\tHow:\n",
        "\t•\tReconstruct the model from the config.\n",
        "\t•\tLoad the current global parameters.\n",
        "\t•\tSave using the HuggingFace save_pretrained method.\n",
        "\n",
        "    🧠 Why This Matters: In federated learning, there’s no single centralized\n",
        "    training process. If something goes wrong, saved checkpoints are your recovery\n",
        "    point.\n",
        "\n",
        "    🔁 Return Format: Always returns 0.0, {} because evaluation is optional here\n",
        "    — the function is used mainly for checkpointing.\n",
        "    \"\"\"\n",
        "\n",
        "    def evaluate(server_round: int, parameters, config):\n",
        "        # Save model\n",
        "        if server_round != 0 and (\n",
        "            server_round == total_round or server_round % save_every_round == 0\n",
        "        ):\n",
        "            # Init model\n",
        "            model = get_model(model_cfg)\n",
        "            set_parameters(model, parameters)\n",
        "\n",
        "            model.save_pretrained(f\"{save_path}/peft_{server_round}\")\n",
        "\n",
        "        return 0.0, {}\n",
        "\n",
        "    return evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cf78077",
      "metadata": {
        "id": "1cf78077"
      },
      "source": [
        "🧩 How It All Fits Together\n",
        "\n",
        "These functions collectively help manage the federated learning lifecycle:\n",
        "- Configure each round (get_on_fit_config)\n",
        "- Aggregate client metrics meaningfully (fit_weighted_average)\n",
        "- Persist model state safely (get_evaluate_fn)\n",
        "\n",
        "🛠️ Next Step: These will be passed into the start_server call when you launch the federated training loop."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb713202",
      "metadata": {
        "id": "bb713202"
      },
      "source": [
        "### Building the Federated Server – Strategy with Differential Privacy 🛡️\n",
        "\n",
        "In this final piece of the federated puzzle, you define the federated learning strategy, optionally enhance it with differential privacy, and configure the server using Flower’s ServerAppComponents.\n",
        "\n",
        "Let’s break this down carefully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0bedbc9",
      "metadata": {
        "id": "a0bedbc9"
      },
      "outputs": [],
      "source": [
        "from flwr.server.strategy import (\n",
        "    DifferentialPrivacyClientSideFixedClipping\n",
        ")\n",
        "\n",
        "def server_fn(context: Context):\n",
        "    \"\"\"\n",
        "    This function returns a configured Flower server app, which will be passed to\n",
        "    start_simulation() later. It defines:\n",
        "\t•\tThe strategy for aggregation (FedAvg)\n",
        "\t•\tHow rounds behave (e.g., which clients to sample)\n",
        "\t•\tOptional advanced features like Differential Privacy\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the Strategy\n",
        "    ## 🔁 FedAvg is the classic federated strategy where model updates are averaged\n",
        "    ## across clients.\n",
        "    strategy = fl.server.strategy.FedAvg(\n",
        "        min_available_clients=cfg.flower.num_clients, # total clients\n",
        "        fraction_fit=cfg.flower.fraction_fit, # ratio of clients to sample\n",
        "        fraction_evaluate=0.0, # No federated evaluation\n",
        "        # A (optional) function used to configure a \"fit()\" round\n",
        "        on_fit_config_fn=get_on_fit_config(),\n",
        "        # A (optional) function to aggregate metrics sent by clients\n",
        "        fit_metrics_aggregation_fn=fit_weighted_average,\n",
        "        # A (optional) function to execute on the server after each round.\n",
        "        # In this example the function only saves the global model.\n",
        "        evaluate_fn=get_evaluate_fn(\n",
        "            cfg.model,\n",
        "            cfg.train.save_every_round,\n",
        "            cfg.flower.num_rounds,\n",
        "            save_path\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Add Differential Privacy\n",
        "    sampled_clients = cfg.flower.num_clients*strategy.fraction_fit\n",
        "    strategy = DifferentialPrivacyClientSideFixedClipping(\n",
        "        strategy,\n",
        "        noise_multiplier=cfg.flower.dp.noise_mult,\n",
        "        clipping_norm=cfg.flower.dp.clip_norm,\n",
        "        num_sampled_clients=sampled_clients\n",
        "    )\n",
        "\n",
        "    # Number of rounds to run the simulation\n",
        "    num_rounds = cfg.flower.num_rounds\n",
        "    config = fl.server.ServerConfig(num_rounds=num_rounds)\n",
        "\n",
        "    return fl.server.ServerAppComponents(strategy=strategy, config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc0a1873",
      "metadata": {
        "id": "cc0a1873"
      },
      "source": [
        "🧩 How This Fits In\n",
        "\n",
        "You’ve now configured:\n",
        "-\tClients: What model/data they use, and how they train\n",
        "-\tServer: How updates are collected, averaged, checkpointed, and protected\n",
        "-\tStrategies: What proportion of clients participate, and how often\n",
        "\n",
        "Now we define the server app!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2768a264",
      "metadata": {
        "id": "2768a264"
      },
      "outputs": [],
      "source": [
        "server = fl.server.ServerApp(server_fn=server_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5393745c",
      "metadata": {
        "id": "5393745c"
      },
      "source": [
        "## 🚀 Step 7: Running the Simulation — Launching Your Federated Learning System 🧠🌐\n",
        "\n",
        "At this point, all components have been prepared. This cell actually starts the simulation — kicking off the training across simulated federated clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "534e33ea",
      "metadata": {
        "id": "534e33ea",
        "outputId": "8bdd717a-f0de-4a41-d3fc-3ca4b6eba305"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=2, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 0.0, {}\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 20)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: central DP noise with 0.0025 stdev added\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.0, {}, 139.0540186750004)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 20)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: central DP noise with 0.0025 stdev added\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.0, {}, 280.93382814699726)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 2 round(s) in 280.93s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 0: 0.0\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.0\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.0\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, fit):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'train_loss': [(1, 2.3728523737255918), (2, 2.365361067125912)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        }
      ],
      "source": [
        "from logging import ERROR\n",
        "\n",
        "client_resources = dict(cfg.flower.client_resources)\n",
        "backend_setup = {\"logging_level\": ERROR, \"log_to_driver\": False}\n",
        "fl.simulation.run_simulation(\n",
        "    server_app=server,\n",
        "    client_app=client,\n",
        "    num_supernodes=cfg.flower.num_clients,\n",
        "    backend_config={\n",
        "        \"client_resources\": client_resources,\n",
        "        \"init_args\": backend_setup\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c761c2c9",
      "metadata": {
        "id": "c761c2c9"
      },
      "source": [
        "## Upload to HuggingFace Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c22525e",
      "metadata": {
        "id": "3c22525e"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "# 1a. Load the base 4-bit Pythia-70M\n",
        "base = AutoModelForCausalLM.from_pretrained(\n",
        "    \"EleutherAI/pythia-70m\",\n",
        "    quantization_config=BitsAndBytesConfig(load_in_4bit=True),\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13f34d86",
      "metadata": {
        "id": "13f34d86"
      },
      "outputs": [],
      "source": [
        "# 1b. Wrap it with your federated fine-tuned adapter\n",
        "peft_model = PeftModel.from_pretrained(\n",
        "    base,\n",
        "    \"my_fl_model/peft_2\",    # path to your adapter folder\n",
        "    is_trainable=False       # inference only\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cea4387",
      "metadata": {
        "id": "7cea4387"
      },
      "outputs": [],
      "source": [
        "merged_model = peft_model.merge_and_unload()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f489ab76",
      "metadata": {
        "id": "f489ab76"
      },
      "source": [
        "### Local save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45ddb666",
      "metadata": {
        "id": "45ddb666",
        "outputId": "72cd1a26-99a1-4f1d-9b8e-62531f866bee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('my_fl_model/merged_pythia70m/tokenizer_config.json',\n",
              " 'my_fl_model/merged_pythia70m/special_tokens_map.json',\n",
              " 'my_fl_model/merged_pythia70m/tokenizer.json')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 3a. Create a local folder\n",
        "output_dir = \"my_fl_model/merged_pythia70m\"\n",
        "\n",
        "# 3b. Save merged model weights & config\n",
        "merged_model.save_pretrained(output_dir)\n",
        "\n",
        "# 3c. Also save tokenizer files for complete deployability\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\", use_fast=True)\n",
        "tokenizer.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0f8a67c",
      "metadata": {
        "id": "a0f8a67c"
      },
      "source": [
        "### Push to HuggingFace Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c49228da",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "cf189f471851436faebe8201ca667ef2"
          ]
        },
        "id": "c49228da",
        "outputId": "43423804-9730-4b0c-9a0c-f139c0d0af60"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf189f471851436faebe8201ca667ef2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# 4a. Authenticate (will prompt in notebook)\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01790c89",
      "metadata": {
        "id": "01790c89",
        "outputId": "69d217fe-ae30-4661-9e3b-e0fc3d65ca9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RepoUrl('https://huggingface.co/tituslhy/pythia-70m-federated_finetuned', endpoint='https://huggingface.co', repo_type='model', repo_id='tituslhy/pythia-70m-federated_finetuned')"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from huggingface_hub import create_repo\n",
        "\n",
        "create_repo(repo_id=\"tituslhy/pythia-70m-federated_finetuned\", private=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b83f5cc9",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "72e5e7cb3bc84f77980b3a2588ef345b"
          ]
        },
        "id": "b83f5cc9",
        "outputId": "43efd0a7-4b98-45cc-c888-d449a4ce73ec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72e5e7cb3bc84f77980b3a2588ef345b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/tituslhy/pythia-70m-federated_finetuned/commit/729de8fca6566ad1075ccee5c07095848a6a946f', commit_message='Initial commit of merged Pythia-70M model', commit_description='', oid='729de8fca6566ad1075ccee5c07095848a6a946f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/tituslhy/pythia-70m-federated_finetuned', endpoint='https://huggingface.co', repo_type='model', repo_id='tituslhy/pythia-70m-federated_finetuned'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from huggingface_hub import upload_folder\n",
        "\n",
        "# 4b. Upload the entire merged folder\n",
        "upload_folder(\n",
        "    repo_id=\"tituslhy/pythia-70m-federated_finetuned\",\n",
        "    folder_path=output_dir,\n",
        "    repo_type=\"model\",\n",
        "    commit_message=\"Initial commit of merged Pythia-70M model\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0918bd99",
      "metadata": {
        "id": "0918bd99"
      },
      "source": [
        "## Test LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c8c1907",
      "metadata": {
        "id": "1c8c1907"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "_ = load_dotenv(find_dotenv())\n",
        "HF_TOKEN = os.getenv(\"HUGGINGFACE_FACE_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "261b57c7",
      "metadata": {
        "id": "261b57c7"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"tituslhy/pythia-70m-federated_finetuned\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"tituslhy/pythia-70m-federated_finetuned\")\n",
        "\n",
        "# Add pad token if missing\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Set pad_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# Define generation parameters\n",
        "generate_kwargs = {\n",
        "    \"do_sample\": True,\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_k\": 50,\n",
        "    \"top_p\": 0.95,\n",
        "}\n",
        "\n",
        "# Initialize HuggingFaceLLM\n",
        "llm = HuggingFaceLLM(\n",
        "    model_name=\"tituslhy/pythia-70m-federated_finetuned\",\n",
        "    tokenizer_name=\"tituslhy/pythia-70m-federated_finetuned\",\n",
        "    context_window=512,\n",
        "    generate_kwargs=generate_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "996beb47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "996beb47",
        "outputId": "d9e2ff2b-fd96-4810-b248-42600be752ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "\n",
              "slightly higher levels of these patients are significantly higher (a higher level of the respective baseline serum levels of the respective patients) with higher levels of the disease than those with high levels of the patient.\n",
              "The prevalence of these patients in our study population is low in patients with a history of chronic obstructive pulmonary disease (COPD), which is one of the leading causes of death in patients of the context of cerebrovascular disease. These patients are now undergoing a second-line treatment with a combination of antiplatelet drugs and antiplatelet and cerebrovascular disease, with the latter being a significant contributor to the severity of the disease.\n",
              "The diagnosis of cerebrovascular disease is usually based on a combination of antiplatelet and cerebrovascular disease with an overall risk factor of mortality to the patients with a history of cerebral ischemia, and the highest level of cerebrovascular disease in these patients. The current diagnosis of cerebrovascular disease is often either in the context of chronic disease, or the definition of the term \"post-mortem\" as defined in this study.\n",
              "The purpose of the current study is to analyse the severity of the disease in this population, as a possible source for the case of the death of a patient with a history of cerebral ischemia and a history of cerebrovascular disease"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "prompt = \"What are the management strategies for antiphospholipid syndrome?\"\n",
        "response = llm.complete(prompt)\n",
        "\n",
        "display(Markdown(str(response)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4FfKpTqOCcj0",
      "metadata": {
        "id": "4FfKpTqOCcj0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
