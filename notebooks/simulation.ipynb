{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d479b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4d58c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acc6da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d76ff75",
   "metadata": {},
   "source": [
    "## üßë‚Äçüç≥ Step 1: Grab the Recipe ‚Äî Load Your Training Configuration\n",
    "\n",
    "Every great dish starts with a recipe ‚Äî and in this notebook, that recipe is your config file.\n",
    "\n",
    "In this step, we‚Äôre using Hydra to load a YAML configuration that defines all the key ingredients and settings for your federated fine-tuning experiment. Think of it as pulling out the instruction card before cooking.\n",
    "\n",
    "üì¶ What this does:\n",
    "- Loads a configuration file (in this case, federated_7b.yml) using Hydra.\n",
    "- Prints out the full config in a readable YAML format, thanks to OmegaConf.\n",
    "\n",
    "> Technically you can use `yaml.load()` too because we are using single, static files. Using Hydra allows us to work with more complex, hierarchical nested structures and dynamically override parts of the config from CLI or code like: `python train.py model=transformer optimizer=adam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "281e1ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "def get_config(config_name: str, config_path: str = \"../config/\"):\n",
    "    with initialize(config_path=config_path, version_base=\"1.1\"):\n",
    "        cfg = compose(config_name=config_name)\n",
    "\n",
    "    return cfg\n",
    "\n",
    "def print_config(config: DictConfig):\n",
    "    print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba89bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_config(\"federated_7b.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82427b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  name: medalpaca/medical_meadow_medical_flashcards\n",
      "model:\n",
      "  name: mistralai/Mistral-7B-v0.1\n",
      "  quantization: 4\n",
      "  gradient_checkpointing: true\n",
      "  use_fast_tokenizer: false\n",
      "  lora:\n",
      "    peft_lora_r: 16\n",
      "    peft_lora_alpha: 64\n",
      "    target_modules:\n",
      "    - q_proj\n",
      "    - v_proj\n",
      "train:\n",
      "  num_rounds: ${flower.num_rounds}\n",
      "  save_every_round: 5\n",
      "  learning_rate_max: 5.0e-05\n",
      "  learning_rate_min: 1.0e-06\n",
      "  seq_length: 512\n",
      "  padding_side: left\n",
      "  evaluate_split: true\n",
      "  training_arguments:\n",
      "    output_dir: null\n",
      "    learning_rate: null\n",
      "    per_device_train_batch_size: 16\n",
      "    gradient_accumulation_steps: 1\n",
      "    logging_steps: 10\n",
      "    num_train_epochs: 3\n",
      "    max_steps: 10\n",
      "    report_to: null\n",
      "    save_steps: 1000\n",
      "    save_total_limit: 10\n",
      "    gradient_checkpointing: ${model.gradient_checkpointing}\n",
      "    lr_scheduler_type: constant\n",
      "client_resources:\n",
      "  num_cpus: 8\n",
      "  num_gpus: 1.0\n",
      "dp:\n",
      "  noise_mult: 0.02\n",
      "  clip_norm: 0.5\n",
      "flower:\n",
      "  num_clients: 20\n",
      "  num_rounds: 200\n",
      "  fraction_fit: 0.8\n",
      "  client_resources:\n",
      "    num_cpus: 8\n",
      "    num_gpus: 1.0\n",
      "  dp:\n",
      "    noise_mult: 0.02\n",
      "    clip_norm: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d074b",
   "metadata": {},
   "source": [
    "## üë®‚Äçüç≥ Step 2: Prepare the Ingredients ‚Äî Format and Partition Your Dataset\n",
    "\n",
    "Every chef knows the importance of prepping ingredients before cooking. In this step, we‚Äôre doing exactly that ‚Äî slicing and dicing our dataset, then portioning it out evenly like we‚Äôre handing out bento boxes to 20 hungry students (aka clients).\n",
    "\n",
    "üì¶ What this does:\n",
    "- üî™ format_dataset: Cleans and standardizes column names so all partitions speak the same language.\n",
    "- üì¶ IidPartitioner: Splits the dataset evenly across clients.\n",
    "- üç± FederatedDataset: Applies the partitioning and prepares it for training.\n",
    "- üìä visualize_partitions: (Optional) Lets us peek at how evenly data is spread.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdbb33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def format_dataset(dataset):\n",
    "    dataset = dataset.remove_columns(['instruction'])\n",
    "    dataset = dataset.rename_column(\"output\", \"response\")\n",
    "    dataset = dataset.rename_column(\"input\", \"instruction\")\n",
    "    return dataset\n",
    "\n",
    "def visualize_partitions(fed_dataset: FederatedDataset):\n",
    "    _ = fed_dataset.load_partition(0)\n",
    "    num_partitions = fed_dataset.partitioners['train'].num_partitions\n",
    "    \n",
    "    plt.bar(range(num_partitions), [len(fed_dataset.load_partition(i)) for i in range(num_partitions)])\n",
    "    plt.xticks(range(num_partitions))\n",
    "    plt.xlabel(\"Partition ID\")\n",
    "    plt.ylabel(\"Number of examples\")\n",
    "    plt.title(f\"IID partitioning into {num_partitions} partitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6ea27b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb7dc5d3bea4f22a2f5f778b6988a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2935738d3a54be59d4181cfb9aa1e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(‚Ä¶)l_meadow_wikidoc_medical_flashcards.json:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6c4aea0de14a86a913211aa659f87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/33955 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'response'],\n",
       "    num_rows: 1698\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitioner = IidPartitioner(num_partitions=cfg.flower.num_clients)\n",
    "fds = FederatedDataset(\n",
    "    dataset=cfg.dataset.name,\n",
    "    partitioners={\"train\": partitioner}\n",
    ")\n",
    "\n",
    "partition_zero = fds.load_partition(0) \n",
    "\n",
    "format_dataset(partition_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb53e724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_partitions(fds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e044507",
   "metadata": {},
   "source": [
    "## üë®‚Äçüç≥ Step 3: Load the Model ‚Äî Then Estimate Your Grocery Bill\n",
    "\n",
    "Now that we‚Äôve got our ingredients sorted and divided, it‚Äôs time to prep the kitchen. Here, we load our model, apply the right quantization, and plug in LoRA adapters to make training lighter. Then we run a quick cost check ‚Äî like scanning your grocery basket before checkout.\n",
    "\n",
    "üì¶ What this does:\n",
    "- üß† Loads your pretrained model (e.g., Mistral, LLaMA).\n",
    "- üíæ Applies quantization for lower memory use (4-bit/8-bit).\n",
    "- üéØ Attaches LoRA adapters ‚Äî a ‚Äújust train these few layers‚Äù approach.\n",
    "- üßÆ Calculates communication costs for 20 simulated clients, across multiple federated rounds.\n",
    "\n",
    "> üìà Why this matters:\n",
    "> Federated fine-tuning isn‚Äôt just about accuracy ‚Äî it‚Äôs also about efficiency. Uploading 7B parameters to 20 clients for 3 rounds? The number of parameters sent by the clients to the server alone can overwhelm it. LoRA cuts that cost by 20x‚Äì100x. It's best to have a helper function to budget your bandwidth before the federated feast begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa99ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import (\n",
    "    PeftModel,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    ")\n",
    "from peft.utils import prepare_model_for_kbit_training\n",
    "from trl import DataCollatorForCompletionOnlyLM, SFTTrainer\n",
    "\n",
    "def get_model(model_cfg: DictConfig):\n",
    "    \"\"\"Load model with appropiate quantization config and\n",
    "    other optimizations.\"\"\"\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    quantization_config = None\n",
    "    model_name = model_cfg.name\n",
    "    if use_cuda:\n",
    "        if model_cfg.quantization == 4:\n",
    "            quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "        elif model_cfg.quantization == 8:\n",
    "            quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Use 4-bit or 8-bit quantization. You passed: {model_cfg.quantization}/\"\n",
    "            )\n",
    "\n",
    "        model_name = model_cfg.name\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quantization_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        low_cpu_mem_usage=True,\n",
    "    )\n",
    "\n",
    "    if use_cuda:\n",
    "        model = prepare_model_for_kbit_training(\n",
    "            model, use_gradient_checkpointing=model_cfg.gradient_checkpointing\n",
    "        )\n",
    "\n",
    "    target_modules = model_cfg.lora.target_modules\n",
    "    if target_modules:\n",
    "        target_modules = list(target_modules)\n",
    "    peft_config = LoraConfig(\n",
    "        r=model_cfg.lora.peft_lora_r,\n",
    "        lora_alpha=model_cfg.lora.peft_lora_alpha,\n",
    "        lora_dropout=0.075,\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=target_modules,\n",
    "    )\n",
    "\n",
    "    peft_model = get_peft_model(model, peft_config)\n",
    "    if not (use_cuda):\n",
    "        peft_model.enable_input_require_grads()\n",
    "\n",
    "    if model_cfg.gradient_checkpointing:\n",
    "        model.config.use_cache = False\n",
    "\n",
    "    return peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cec84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_communication_costs(config, comm_bw_mbps: float = 20):\n",
    "    model = get_model(config.model)\n",
    "\n",
    "    trainable, all_parameters = model.get_nb_trainable_parameters()\n",
    "\n",
    "    total_size = 4*all_parameters/(1024**2)\n",
    "    trainable_size = 4*trainable/(1024**2)\n",
    "\n",
    "    upload_time_total = total_size/(comm_bw_mbps/8)\n",
    "    upload_time_finetune = trainable_size/(comm_bw_mbps/8)\n",
    "    \n",
    "    print(f\"Full model:\\n\\t{all_parameters/1e6:.3f} M parameters\\n\\t{total_size:.2f} MB --> upload in {upload_time_total:.2f}s @ {comm_bw_mbps}Mbps\")\n",
    "    print(f\"Finetuned model:\\n\\t{trainable/1e6:.3f} M parameters\\n\\t{trainable_size:.2f} MB --> upload in {upload_time_finetune:.2f}s @ {comm_bw_mbps}Mbps\")\n",
    "    # print(f\"In a {comm_bw_mbps} Mbps channel --> {}\")\n",
    "\n",
    "    num_rounds = config.flower.num_rounds\n",
    "    num_clients_per_round = int(config.flower.num_clients * config.flower.fraction_fit)\n",
    "    print(f\"Federated Learning setting: \"\n",
    "          f\"\\n\\tNumber of rounds: {num_rounds}\"\n",
    "          f\"\\n\\tNumber of clients per round: {num_clients_per_round}\")\n",
    "    \n",
    "    print(f\"-----------------------------------------------\")\n",
    "    print(f\"Total Communication costs (Full model): {2*num_rounds*num_clients_per_round*total_size/1024:.1f} GB\")\n",
    "    print(f\"Total Communication costs (Finetuning): {2*num_rounds*num_clients_per_round*trainable_size} MB\")\n",
    "    print(f\"Communication savings: {all_parameters/trainable:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5758864",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_communication_costs(cfg, comm_bw_mbps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d3ae7",
   "metadata": {},
   "source": [
    "## üë®‚Äçüç≥ Step 4: Prompt Prep ‚Äî Set the Table for Fine-Tuning\n",
    "\n",
    "Before we can start cooking (i.e., training), we need to set the table properly. That means formatting the prompts, choosing the right tokenizer, and preparing a smart data collator that knows where the ‚Äúresponse‚Äù part starts.\n",
    "\n",
    "üß† What‚Äôs happening here:\n",
    "- üî§ Loads the tokenizer and sets a pad token (beginning-of-sequence or end-of-sequence depending on the model).\n",
    "- üìå Finds the location in the prompt where the model should start predicting ‚Äî right after \"### Response:\".\n",
    "- üßº The `DataCollatorForCompletionOnlyLM` ensures that only the response gets masked for loss ‚Äî so we train the model only on what it should generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41691bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    # Constructing a standard Alpaca (https://github.com/tatsu-lab/stanford_alpaca#data-release) prompt\n",
    "    mssg = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "    for i in range(len(example[\"instruction\"])):\n",
    "        text = f\"{mssg}\\n### Instruction:\\n{example['instruction'][i]}\\n### Response: {example['response'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "def get_tokenizer_and_data_collator_and_prompt_formatting(\n",
    "    model_name: str, use_fast: bool, padding_side: str\n",
    "):\n",
    "\n",
    "    # From: https://huggingface.co/docs/trl/en/sft_trainer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name, use_fast=use_fast, padding_side=padding_side\n",
    "    )\n",
    "\n",
    "    tokenizer.pad_token = (\n",
    "        tokenizer.bos_token if padding_side == \"left\" else tokenizer.eos_token\n",
    "    )\n",
    "    response_template_with_context = \"\\n### Response:\"  # alpaca response tag\n",
    "    response_template_ids = tokenizer.encode(\n",
    "        response_template_with_context, add_special_tokens=False\n",
    "    )[2:]\n",
    "    data_collator = DataCollatorForCompletionOnlyLM(\n",
    "        response_template_ids, tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    return tokenizer, data_collator, formatting_prompts_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a092fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, data_collator, formatting_prompts_func = get_tokenizer_and_data_collator_and_prompt_formatting(\n",
    "    cfg.model.name, \n",
    "    cfg.model.use_fast_tokenizer,\n",
    "    cfg.train.padding_side,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837cc82c",
   "metadata": {},
   "source": [
    "## üç≥ Step 5: Crafting the Flower Client ‚Äì The Heartbeat of Federated Learning\n",
    "\n",
    "In the realm of federated learning, the client is not just a participant; it‚Äôs the linchpin that holds the decentralized training process together. Think of it as a dedicated chef in a distributed kitchen, each working with their unique ingredients (data) but following a shared recipe (model architecture).\n",
    "\n",
    "üß† Understanding the Client‚Äôs Role\n",
    "\n",
    "In Flower‚Äôs architecture, each client is responsible for:\n",
    "1.\tReceiving the Global Model: The server sends the current global model parameters to the client.\n",
    "2.\tLocal Training: The client trains the model on its local dataset, ensuring data privacy and compliance with data governance policies.\n",
    "3.\tSending Updates: After training, the client sends the updated model parameters back to the server for aggregation.\n",
    "\n",
    "This process allows for collaborative model training without the need to centralize sensitive data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6794ca25",
   "metadata": {},
   "source": [
    "Here's our utility function to adjust our learning rate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea60408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def cosine_annealing(\n",
    "    current_round: int,\n",
    "    total_round: int,\n",
    "    lrate_max: float = 0.001,\n",
    "    lrate_min: float = 0.0,\n",
    ") -> float:\n",
    "    \"\"\"Implement cosine annealing learning rate schedule.\"\"\"\n",
    "\n",
    "    cos_inner = math.pi * current_round / total_round\n",
    "    return lrate_min + 0.5 * (lrate_max - lrate_min) * (1 + math.cos(cos_inner))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a0b8f4",
   "metadata": {},
   "source": [
    "üõ†Ô∏è Implementing the Flower Client\n",
    "\n",
    "Let‚Äôs delve into the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import Context\n",
    "from flwr.common.typing import NDArrays, Scalar\n",
    "from fl.client import NumPyClient\n",
    "\n",
    "from typing import Dict, Tuple, Callable\n",
    "from collections import OrderedDict\n",
    "\n",
    "def set_parameters(model, parameters: NDArrays) -> None:\n",
    "    \"\"\"Change the parameters of the model using the given ones.\"\"\"\n",
    "    peft_state_dict_keys = get_peft_model_state_dict(model).keys()\n",
    "    params_dict = zip(peft_state_dict_keys, parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    set_peft_model_state_dict(model, state_dict)\n",
    "\n",
    "class FlowerClient(NumPyClient): \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_cfg: DictConfig,\n",
    "        train_cfg: DictConfig,\n",
    "        trainset,\n",
    "        tokenizer,\n",
    "        formatting_prompts_func,\n",
    "        data_collator,\n",
    "        save_path,\n",
    "    ):  \n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.train_cfg = train_cfg\n",
    "        self.training_argumnets = TrainingArguments(**train_cfg.training_arguments)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.formatting_prompts_func = formatting_prompts_func\n",
    "        self.data_collator = data_collator\n",
    "        self.save_path = save_path\n",
    "\n",
    "        # instantiate model\n",
    "        self.model = get_model(model_cfg)\n",
    "\n",
    "        self.trainset = trainset\n",
    "\n",
    "    def get_parameters(self, config: Dict[str, Scalar]) -> NDArrays:\n",
    "        \"\"\"Return the parameters of the current net.\"\"\"\n",
    "\n",
    "        state_dict = get_peft_model_state_dict(self.model)\n",
    "        return [val.cpu().numpy() for _, val in state_dict.items()]\n",
    "\n",
    "    def fit(\n",
    "        self, parameters: NDArrays, config: Dict[str, Scalar]\n",
    "    ) -> Tuple[NDArrays, int, Dict]:\n",
    "        \"\"\"Implement distributed fit function for a given client.\"\"\"\n",
    "        set_parameters(self.model, parameters)\n",
    "\n",
    "        new_lr = cosine_annealing(\n",
    "            int(config[\"current_round\"]),\n",
    "            self.train_cfg.num_rounds,\n",
    "            self.train_cfg.learning_rate_max,\n",
    "            self.train_cfg.learning_rate_min,\n",
    "        )\n",
    "\n",
    "        self.training_argumnets.learning_rate = new_lr\n",
    "        self.training_argumnets.output_dir = self.save_path\n",
    "\n",
    "        evalset = None\n",
    "        if self.train_cfg.evaluate_split:\n",
    "            train_test = self.trainset.train_test_split(test_size=0.1, seed=1234)\n",
    "            trainset = train_test['train']\n",
    "            evalset = train_test['test']\n",
    "        else:\n",
    "            trainset = self.trainset\n",
    "\n",
    "        trainer = SFTTrainer(\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            args=self.training_argumnets,\n",
    "            max_seq_length=self.train_cfg.seq_length,\n",
    "            train_dataset=trainset,\n",
    "            eval_dataset=evalset,\n",
    "            formatting_func=self.formatting_prompts_func,\n",
    "            data_collator=self.data_collator,\n",
    "        )\n",
    "\n",
    "        metrics = {}\n",
    "        if self.train_cfg.evaluate_split:\n",
    "            eval_res = trainer.evaluate()\n",
    "            metrics['eval_loss'] = eval_res['eval_loss']\n",
    "            print(eval_res)\n",
    "\n",
    "        # Do local training\n",
    "        results = trainer.train()\n",
    "\n",
    "        metrics = {**metrics, \"train_loss\": results.training_loss}\n",
    "\n",
    "        return (\n",
    "            self.get_parameters({}),\n",
    "            len(self.trainset),\n",
    "            metrics,\n",
    "        )\n",
    "\n",
    "def gen_client_fn(\n",
    "    fds,\n",
    "    tokenizer,\n",
    "    formatting_prompts_func,\n",
    "    data_collator,\n",
    "    model_cfg: DictConfig,\n",
    "    train_cfg: DictConfig,\n",
    "    save_path: str,\n",
    ") -> Callable[[str], FlowerClient]:  \n",
    "    \"\"\"Generate the client function that creates the Flower Clients.\"\"\"\n",
    "\n",
    "    def client_fn(context: Context) -> FlowerClient:\n",
    "        \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "        # Let's get the partition corresponding to the i-th client\n",
    "        partition_id = int(context.node_config[\"partition-id\"])\n",
    "        client_trainset = fds.load_partition(partition_id, \"train\")\n",
    "        client_trainset = client_trainset.remove_columns([\"instruction\"])\n",
    "        client_trainset = client_trainset.rename_column(\"input\", \"instruction\")\n",
    "        client_trainset = client_trainset.rename_column(\"output\", \"response\")\n",
    "        return FlowerClient(\n",
    "            model_cfg,\n",
    "            train_cfg,\n",
    "            client_trainset,\n",
    "            tokenizer,\n",
    "            formatting_prompts_func,\n",
    "            data_collator,\n",
    "            save_path,\n",
    "        ).to_client()\n",
    "\n",
    "    return client_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a19b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.client.mod import fixedclipping_mod\n",
    "\n",
    "save_path = \"./my_fl_model\"\n",
    "client = fl.client.ClientApp(\n",
    "    client_fn=gen_client_fn(\n",
    "        fds,\n",
    "        tokenizer,\n",
    "        formatting_prompts_func,\n",
    "        data_collator,\n",
    "        cfg.model, \n",
    "        cfg.train, \n",
    "        save_path,\n",
    "    ),\n",
    "    mods=[fixedclipping_mod] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d1bb8",
   "metadata": {},
   "source": [
    "üîç Key Components Explained\n",
    "- `set_parameters`: Updates the model‚Äôs parameters with those received from the server.\n",
    "- `FlowerClient` Class: Inherits from NumPyClient and implements the core methods:\n",
    "- `get_parameters`: Retrieves the current model parameters.\n",
    "- `fit`: Trains the model on local data and returns the updated parameters along with training metrics.\n",
    "- `gen_client_fn`: Generates a function to create `FlowerClient` instances, each corresponding to a unique data partition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff69d0aa",
   "metadata": {},
   "source": [
    "### üåê The Bigger Picture\n",
    "\n",
    "In Flower‚Äôs architecture, the client plays a pivotal role in the federated learning process. \n",
    "\n",
    "By handling local training and maintaining data privacy, clients enable the collaborative development of robust models without the need for centralized data storage. This approach is especially beneficial in scenarios where data is sensitive or distributed across various locations.\n",
    "\n",
    "For a deeper dive into Flower‚Äôs architecture and the role of clients, you can refer to the [Flower Architecture Documentation](https://flower.ai/docs/framework/explanation-flower-architecture.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d581e8",
   "metadata": {},
   "source": [
    "## üß† Step 6: Configuring the Federated Server ‚Äì Directing the Symphony üéª\n",
    "\n",
    "While each client trains locally, the server acts as the conductor of the federated learning orchestra. It defines how rounds are configured, how model updates are aggregated, and when models are saved.\n",
    "\n",
    "This cell introduces three essential server-side functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b479a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import Context\n",
    "\n",
    "def get_on_fit_config():\n",
    "    \"\"\"\n",
    "    ‚Ä¢\tPurpose: This function provides the configuration dictionary sent to each \n",
    "    client before training begins in a given round.\n",
    "\t‚Ä¢\tUse Case: Clients can adapt behaviors (e.g., learning rate schedules) based\n",
    "    on the current round number.\n",
    "\t‚Ä¢\tDesign Pattern: Returns a function (fit_config_fn) that Flower calls at each\n",
    "    round.\n",
    "\n",
    "    üß† Analogy: This is like giving each chef a new cooking instruction every day \n",
    "    based on how many days the kitchen has been operating.\n",
    "    \n",
    "    \"\"\"\n",
    "    def fit_config_fn(server_round: int):\n",
    "        fit_config = {\"current_round\": server_round}\n",
    "        return fit_config\n",
    "\n",
    "    return fit_config_fn\n",
    "\n",
    "def fit_weighted_average(metrics):\n",
    "    \"\"\"\n",
    "    ‚Ä¢\tPurpose: Calculates a weighted average of training loss across all clients.\n",
    "    ‚Ä¢\tMechanism:\n",
    "        ‚Ä¢\tEach client‚Äôs training loss is scaled by the number of examples it used.\n",
    "        ‚Ä¢\tThis ensures larger datasets have more influence on the final average.\n",
    "    ‚Ä¢\tWhy It Matters: Without weighting, small datasets could skew the overall metric.\n",
    "    \n",
    "    Example:\n",
    "    # Client 1: 100 examples, loss = 0.5 ‚Üí 100 * 0.5 = 50\n",
    "    # Client 2: 200 examples, loss = 0.25 ‚Üí 200 * 0.25 = 50\n",
    "    # Weighted average = (50 + 50) / (100 + 200) = 0.333\n",
    "    \"\"\"\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    losses = [num_examples * m[\"train_loss\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"train_loss\": sum(losses) / sum(examples)}\n",
    "\n",
    "def get_evaluate_fn(model_cfg, save_every_round, total_round, save_path):\n",
    "    \"\"\"\n",
    "    ‚Ä¢\tPurpose: Save the global model periodically during training.\n",
    "\t‚Ä¢\tConditions:\n",
    "\t‚Ä¢\tSkip round 0.\n",
    "\t‚Ä¢\tSave if it‚Äôs the final round or every n rounds (save_every_round).\n",
    "\t‚Ä¢\tHow:\n",
    "\t‚Ä¢\tReconstruct the model from the config.\n",
    "\t‚Ä¢\tLoad the current global parameters.\n",
    "\t‚Ä¢\tSave using the HuggingFace save_pretrained method.\n",
    "\n",
    "    üß† Why This Matters: In federated learning, there‚Äôs no single centralized \n",
    "    training process. If something goes wrong, saved checkpoints are your recovery \n",
    "    point.\n",
    "\n",
    "    üîÅ Return Format: Always returns 0.0, {} because evaluation is optional here \n",
    "    ‚Äî the function is used mainly for checkpointing.\n",
    "    \"\"\"\n",
    "\n",
    "    def evaluate(server_round: int, parameters, config):\n",
    "        # Save model\n",
    "        if server_round != 0 and (\n",
    "            server_round == total_round or server_round % save_every_round == 0\n",
    "        ):\n",
    "            # Init model\n",
    "            model = get_model(model_cfg)\n",
    "            set_parameters(model, parameters)\n",
    "\n",
    "            model.save_pretrained(f\"{save_path}/peft_{server_round}\")\n",
    "\n",
    "        return 0.0, {}\n",
    "\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf78077",
   "metadata": {},
   "source": [
    "üß© How It All Fits Together\n",
    "\n",
    "These functions collectively help manage the federated learning lifecycle:\n",
    "- Configure each round (get_on_fit_config)\n",
    "- Aggregate client metrics meaningfully (fit_weighted_average)\n",
    "- Persist model state safely (get_evaluate_fn)\n",
    "\n",
    "üõ†Ô∏è Next Step: These will be passed into the start_server call when you launch the federated training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb713202",
   "metadata": {},
   "source": [
    "### Building the Federated Server ‚Äì Strategy with Differential Privacy üõ°Ô∏è\n",
    "\n",
    "In this final piece of the federated puzzle, you define the federated learning strategy, optionally enhance it with differential privacy, and configure the server using Flower‚Äôs ServerAppComponents.\n",
    "\n",
    "Let‚Äôs break this down carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bedbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.server.strategy import (\n",
    "    DifferentialPrivacyClientSideFixedClipping\n",
    ")\n",
    "\n",
    "def server_fn(context: Context):\n",
    "    \"\"\"\n",
    "    This function returns a configured Flower server app, which will be passed to \n",
    "    start_simulation() later. It defines:\n",
    "\t‚Ä¢\tThe strategy for aggregation (FedAvg)\n",
    "\t‚Ä¢\tHow rounds behave (e.g., which clients to sample)\n",
    "\t‚Ä¢\tOptional advanced features like Differential Privacy\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the Strategy\n",
    "    ## üîÅ FedAvg is the classic federated strategy where model updates are averaged\n",
    "    ## across clients.\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "        min_available_clients=cfg.flower.num_clients, # total clients\n",
    "        fraction_fit=cfg.flower.fraction_fit, # ratio of clients to sample\n",
    "        fraction_evaluate=0.0, # No federated evaluation\n",
    "        # A (optional) function used to configure a \"fit()\" round\n",
    "        on_fit_config_fn=get_on_fit_config(),\n",
    "        # A (optional) function to aggregate metrics sent by clients\n",
    "        fit_metrics_aggregation_fn=fit_weighted_average,\n",
    "        # A (optional) function to execute on the server after each round. \n",
    "        # In this example the function only saves the global model.\n",
    "        evaluate_fn=get_evaluate_fn( \n",
    "            cfg.model,\n",
    "            cfg.train.save_every_round,\n",
    "            cfg.flower.num_rounds,\n",
    "            save_path\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Add Differential Privacy\n",
    "    sampled_clients = cfg.flower.num_clients*strategy.fraction_fit\n",
    "    strategy = DifferentialPrivacyClientSideFixedClipping(\n",
    "        strategy, \n",
    "        noise_multiplier=cfg.flower.dp.noise_mult,\n",
    "        clipping_norm=cfg.flower.dp.clip_norm, \n",
    "        num_sampled_clients=sampled_clients\n",
    "    )\n",
    "\n",
    "    # Number of rounds to run the simulation\n",
    "    num_rounds = cfg.flower.num_rounds\n",
    "    config = fl.server.ServerConfig(num_rounds=num_rounds)\n",
    "    \n",
    "    return fl.server.ServerAppComponents(strategy=strategy, config=config) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a1873",
   "metadata": {},
   "source": [
    "üß© How This Fits In\n",
    "\n",
    "You‚Äôve now configured:\n",
    "-\tClients: What model/data they use, and how they train\n",
    "-\tServer: How updates are collected, averaged, checkpointed, and protected\n",
    "-\tStrategies: What proportion of clients participate, and how often\n",
    "\n",
    "Now we define the server app!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2768a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = fl.server.ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5393745c",
   "metadata": {},
   "source": [
    "## üöÄ Step 7: Running the Simulation ‚Äî Launching Your Federated Learning System üß†üåê\n",
    "\n",
    "At this point, all components have been prepared. This cell actually starts the simulation ‚Äî kicking off the training across simulated federated clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e33ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import ERROR\n",
    "\n",
    "client_resources = dict(cfg.flower.client_resources)\n",
    "backend_setup = {\"logging_level\": ERROR, \"log_to_driver\": False}\n",
    "fl.simulation.run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=cfg.flower.num_clients,\n",
    "    backend_config={\n",
    "        \"client_resources\": client_resources,\n",
    "        \"init_args\": backend_setup\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
